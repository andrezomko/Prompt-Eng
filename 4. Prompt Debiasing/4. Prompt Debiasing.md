#### Model Guessing Your Intentions

#### Sensitivity to Prompt Phrasing
- prompts are well-phrased and clear

#### Plausible but Incorrect Answers 
-  sounds plausible but are actually incorrect

#### Verbose or Overly Technical Responses 
- asking for a simpler response, or requesting a particular format.

#### Citing sources
- cause no access to the internet

#### Hallucinations
- sometimes the LLMs goes MAD in the case of not knowing an answer.
###  [[2.5 Least to Most]] fixes it:

#### LLMs Not Asking for Clarification 
- Ambiguous prompt, LLMs might try to answer it without asking for more info.
- Prompt : “If the question is unclear, please ask for clarification.”
#### Failure to Perform Multi-part Tasks
-  Breaking the task into smaller, more manageable sub-tasks