##### Specify 
- the problem type, expected input format, and desired output format.

###### Avoid ambiguous or vague instructions 
- [[2. Prompting Techniques]]

###### Example-based prompts:
- [[2.2 Few Shot prompting]]

###### Step-by-step instructions
- [[2.3 Chain of Thought]] 

###### Anticipate potential errors or misconceptions 
- Provide guidance on common mistake

###### Continuously evaluate the model
- responses and iterate on the prompts based on user feedback.
-  [[LLM Self Evaluation]]

###### Progressive disclosure:
- revelar as informacoes ou subtasks gradualmente ao inves do problema todo de uma vez so.
- [[2.4 Zero Shot Chain of Thought]]
- [[2.5 Least to Most]] 

###### Sanity checks
- ask the model to show intermediate steps or validate the solution against known mathematical properties.

###### Fine-tuning and experimentation:


### [[LLM Self Evaluation]] (auto aprendizado da LLM)
### [[Calibrating LLMS]] (rankings, temperatura)
### [[Prompt Debiasing]] 
### [[Prompt Ensembling]] (LLMs avaliando outros LLMs)

